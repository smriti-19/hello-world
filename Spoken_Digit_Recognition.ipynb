{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spoken Digit Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smriti-19/hello-world/blob/main/Spoken_Digit_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkmqkomLyjyN",
        "outputId": "22d7a79b-acdb-4826-a2fb-4b6e6228f292"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RC2NvlPw823"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy\n",
        "import os\n",
        "from sklearn.preprocessing import normalize\n",
        "import random\n",
        "from scipy.fftpack import fft\n",
        "from scipy.io import wavfile # get the api"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weWeJq_MyYm_"
      },
      "source": [
        "# calculating the modulus of the signal\n",
        "def mod(v1):\n",
        "    sum=0\n",
        "    for i in range(v1.shape[0]):\n",
        "        sum+=v1[i]**2\n",
        "    return sum/2\n",
        "\n",
        "#determining the correlation between two signals\n",
        "def correlation(v1,v2):\n",
        "    corr = 0\n",
        "    for i in range(v1.shape[0]):\n",
        "        corr+=v1[i]*v2[i]\n",
        "    return corr\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZbAHkbVzK2D"
      },
      "source": [
        "# creating the reference samples by averaging out the frequency spectrum for each digit\n",
        "fft_list = list()\n",
        "for j in range(25,50):\n",
        "    each_list = list()\n",
        "    for i in range(10):\n",
        "\n",
        "        # read the .wav file\n",
        "        fs, data = wavfile.read('/content/drive/MyDrive/free-spoken-digit-dataset/recordings/'+ str(i)+'_jackson_'+str(j)+'.wav') # load the data\n",
        "\n",
        "        a = list(data)  # this is a two channel soundtrack, I get the first track\n",
        "\n",
        "        b=[(ele/2**8.)*2-1 for ele in a] # this is 8-bit track, b is now normalized on [-1,1)\n",
        "\n",
        "        c = fft(b) # calculate fourier transform (complex numbers list)\n",
        "\n",
        "        d = int(len(c)/2)  # you only need half of the fft list (real signal symmetry)\n",
        "\n",
        "        # pad the sequence so that all spectrums are of the same length (5000)\n",
        "        if(d-1>5000):\n",
        "            each_list.append(abs(c[:5000]))\n",
        "            print(abs(c[:5000].shape))\n",
        "        else:\n",
        "            q = np.pad(abs(c[:d-1]),(0,5000-(d-1)),'constant')\n",
        "        q = np.reshape(q,(q.shape[0],1))\n",
        "        q = normalize(q, axis = 0)\n",
        "        q = np.reshape(q,(q.shape[0]))\n",
        "        each_list.append(q)\n",
        "\n",
        "    fft_list.append(each_list)\n",
        "data = np.array(fft_list)\n",
        "\n",
        "# average taken for all samples\n",
        "final_data = np.average(data,axis=0)\n",
        "fft_list = list(final_data)\n",
        "\n",
        "\n",
        "# depicting the performance of the idea using autocorrelation from reference samples\n",
        "for j in range(10):\n",
        "    corr_list=list()\n",
        "    for i in range(10):\n",
        "        corr_list.append(correlation(fft_list[j],fft_list[i])-mod(fft_list[i]))\n",
        "    # ax = plt.subplot(10,1,j+1)\n",
        "    plt.plot(corr_list)\n",
        "    plt.title(str(j)+ \" correlation\")\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZLw15SnzlVh"
      },
      "source": [
        "directory =\"drive/My Drive/free-spoken-digit-dataset/recordings/\"\n",
        "num=0\n",
        "\n",
        "# testing the work using data samples for the test dataset\n",
        "for k in range(10):\n",
        "    for l in range(0,25): # change this for test set\n",
        "        random_file = str(k)+'_jackson_' + str(l)+'.wav'\n",
        "        print(random_file)\n",
        "        fs_test, data_test = wavfile.read(directory+random_file) # load the data\n",
        "        a_test = data_test\n",
        "        b_test=[(ele/2**8.)*2-1 for ele in a_test]\n",
        "        c_test = fft(b_test) # calculate fourier transform (complex numbers list)\n",
        "\n",
        "        d = int(len(c_test)/2)\n",
        "\n",
        "        # padding sequences\n",
        "\n",
        "        if(d-1>5000):\n",
        "            fft_list.append(abs(c_test[:5000]))\n",
        "            q = abs(c_test[:5000].shape)\n",
        "        else:\n",
        "            q = np.pad(abs(c_test[:d-1]),(0,5000-(d-1)),'constant')\n",
        "        q = np.reshape(q,(q.shape[0],1))\n",
        "        q = normalize(q, axis = 0)\n",
        "        q = np.reshape(q,(q.shape[0]))\n",
        "        corr_list_test = list()\n",
        "        max_num = correlation(q,fft_list[0])-mod(fft_list[0])\n",
        "        max_index = 0\n",
        "        for i in range(10):\n",
        "\n",
        "            # determining the maximum achieved after cross-correlation\n",
        "\n",
        "            corr_list_test.append(correlation(q,fft_list[i])-mod(fft_list[i]))\n",
        "            if(max_num<correlation(q,fft_list[i])-mod(fft_list[i])):\n",
        "                max_num = correlation(q,fft_list[i])-mod(fft_list[i])\n",
        "                max_index = i\n",
        "        if(max_index==k):\n",
        "            num+=1  # correctly classified examples\n",
        "\n",
        "print(str(num/5) + \"% Is the accuracy of the system\")\n",
        "print(\"Predicted number is \" + str(max_index))\n",
        "plt.plot(corr_list_test)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_wave_file(filename, template_size):\n",
        "    # read the .wav file\n",
        "    fs, data = wavfile.read(filename) # load the data\n",
        "\n",
        "    soundtrack_signal = list(data)  # this is a two channel soundtrack, I get the first track\n",
        "\n",
        "    time_signal =[(ele/2**8.)*2-1 for ele in soundtrack_signal] # this is 8-bit track, b is now normalized on [-1,1)\n",
        "\n",
        "    freq_signal = fft(time_signal) # calculate fourier transform (complex numbers list)\n",
        "\n",
        "    d = len(freq_signal)//2  # you only need half of the fft list (real signal symmetry)\n",
        "\n",
        "    # pad the sequence so that all spectrums are of the same length (template_size)\n",
        "    fft_signal = normalize_signal_length(freq_signal, template_size, d)\n",
        "    \n",
        "\n",
        "    time_signal = np.array(time_signal)\n",
        "    time_signal = normalize_signal_length(time_signal, template_size, len(time_signal))\n",
        "    \n",
        "\n",
        "    return fft_signal, time_signal\n",
        "\n",
        "\n",
        "def normalize_signal_length(signal, template_size, intended_size):\n",
        "\n",
        "    if(intended_size-1>template_size):\n",
        "        signal = abs(signal[:template_size])\n",
        "        \n",
        "    else:\n",
        "        signal = np.pad(abs(signal[:intended_size-1]),(0,template_size-(intended_size-1)),'constant')\n",
        "    signal = np.reshape(signal,(signal.shape[0],1))\n",
        "    signal = normalize(signal, axis = 0)\n",
        "    signal = np.reshape(signal,(signal.shape[0]))\n",
        "    \n",
        "    return signal\n",
        "\n",
        "def predict_digit(digit_template, signal):\n",
        "    max_correlation = 0\n",
        "    number_identified = -1\n",
        "    for k in range(len(digit_template)):\n",
        "        corr = correlation(signal, digit_template[k]) - mod(digit_template[k])\n",
        "        if corr>max_correlation:\n",
        "          max_correlation = corr\n",
        "          number_identified = k\n",
        "    return number_identified, max_correlation\n",
        "        \n",
        "\n"
      ],
      "metadata": {
        "id": "Y-yUomSpCeOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfhrqgJZ1mtC"
      },
      "source": [
        "from tempfile import template\n",
        "from numpy.lib.function_base import average\n",
        "fft_digit_template = list()\n",
        "time_digit_template = list()\n",
        "template_size = 2000\n",
        "directory = '/content/drive/MyDrive/free-spoken-digit-dataset/recordings/'\n",
        "for i in range(10):\n",
        "    fft_signal_template = np.zeros((template_size))\n",
        "    time_signal_template = np.zeros((template_size))\n",
        "    num_examples = 0\n",
        "    for j in range(15,50):\n",
        "\n",
        "        # read the .wav file\n",
        "\n",
        "        audio_file = directory + str(i)+'_jackson_'+str(j)+'.wav'\n",
        "        fft_signal, time_signal  = read_wave_file(audio_file, template_size)\n",
        "        fft_signal_template +=fft_signal\n",
        "        time_signal_template += time_signal\n",
        "        num_examples+=1\n",
        "\n",
        "    fft_digit_template.append(fft_signal_template/num_examples)\n",
        "    time_digit_template.append(time_signal_template/num_examples)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = list()\n",
        "pred_labels = list()\n",
        "count = 0\n",
        "for i in range(10):\n",
        "    \n",
        "    for j in range(0,15):\n",
        "\n",
        "        # read the .wav file\n",
        "        filename = directory + str(i)+'_jackson_'+str(j)+'.wav'\n",
        "        fft_signal, time_signal = read_wave_file(filename, template_size)\n",
        "        num_time, max_cor_time = predict_digit(time_digit_template, time_signal)\n",
        "        num_freq, max_cor_freq = predict_digit(fft_digit_template, fft_signal)\n",
        "\n",
        "        \n",
        "        true_labels.append(i)\n",
        "        \n",
        "        pred_labels.append(num_freq)\n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "mGtqXLx46d7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(true_labels, pred_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LRqaI0A8Jf_",
        "outputId": "5a02a325-3cdf-40c0-e68d-f839c315c0af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5866666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIu6XIgp8VhT",
        "outputId": "1f545b57-33a8-49b5-ca55-6c52c0eb38c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDV-1wHOO3GM",
        "outputId": "3c349dcf-6a5e-4fb7-a2a6-ef0d144c51b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18666666666666668"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "3 experiments\n",
        "1. Average signals in time domain from train set and use that as template for cross-correlation matching -> score of 41.33%\n",
        "2. Average signals in freq domain from train set and use that as template for cross-correlation matching -> score of 58.67%\n",
        "3. Taking maximum value of correlation from both time and frequency for matching -> score of 46%\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "OcPwoDl1O7e9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}